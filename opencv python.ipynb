{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fundamentals with opencv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mouse as a Paint-Brush"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw circle in an image with mouse event (Left button double click)\n",
    "\n",
    "import numpy as np\n",
    "from cv2 import cv2\n",
    "\n",
    "# mouse callback function\n",
    "def draw_circle(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDBLCLK:\n",
    "        cv2.circle(img,(x,y),100,(255,0,0),-1)\n",
    "\n",
    "# Create a black image, a window and bind the function to window\n",
    "img = np.ones((512, 512, 3), np.uint8)\n",
    "cv2.namedWindow('image')\n",
    "cv2.setMouseCallback('image', draw_circle)\n",
    "\n",
    "while(1):\n",
    "    cv2.imshow('image', img)\n",
    "    if cv2.waitKey(20) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw rectange and circle in an image with mouse events and toggle between rectange and circle\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "drawing = False # True if mouse is pressed\n",
    "mode = True # if True, draw rectangle, else circle. Press 'm' to toggle\n",
    "ix, iy = -1, -1\n",
    "\n",
    "def draw_circle(event, x, y, flags, param):\n",
    "    global ix, iy, drawing, mode\n",
    "    \n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "        ix, iy = x, y\n",
    "    \n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if drawing == True:\n",
    "            if mode == True:\n",
    "                cv2.rectangle(img, (ix, iy), (x, y), (255, 0, 0), -1)\n",
    "            else:\n",
    "                cv2.circle(img, (x, y), 5, (0, 255, 0), -1)\n",
    "    \n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        drawing = False\n",
    "        if mode == True:\n",
    "            cv2.rectangle(img, (ix, iy), (x, y), (255, 0, 0), -1)\n",
    "        else:\n",
    "            cv2.circle(img, (x, y), 5, (0, 255, 0), -1)\n",
    "\n",
    "\n",
    "img = np.zeros((512, 512, 3), np.uint8)\n",
    "cv2.namedWindow('Image Canvas')\n",
    "cv2.setMouseCallback('Image Canvas', draw_circle)\n",
    "\n",
    "while(1):\n",
    "    cv2.imshow('Image Canvas', img)\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == ord('m'):\n",
    "        mode = not mode\n",
    "    elif k == 27:\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trackbar as the Color Palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a trackbar application to select the color\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# function for trackbar application\n",
    "def nothing(arg):\n",
    "    pass\n",
    "\n",
    "# create an image and window\n",
    "img = np.zeros((512, 512, 3), np.uint8)\n",
    "cv2.namedWindow('Image', cv2.WINDOW_NORMAL)\n",
    "\n",
    "cv2.createTrackbar('R', 'Image', 0, 255, nothing)\n",
    "cv2.createTrackbar('G', 'Image', 0, 255, nothing)\n",
    "cv2.createTrackbar('B', 'Image', 0, 255, nothing)\n",
    "\n",
    "# create a switch for ON/OFF functionality\n",
    "switch = 'ON : 1 \\n OFF : 0'\n",
    "cv2.createTrackbar(switch, 'Image', 0, 1, nothing)\n",
    "while(1):\n",
    "    cv2.imshow('Image', img)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "    \n",
    "    # get trackbar positions\n",
    "    r = cv2.getTrackbarPos('R', 'Image')\n",
    "    b = cv2.getTrackbarPos('B', 'Image')\n",
    "    g = cv2.getTrackbarPos('G', 'Image')\n",
    "    \n",
    "    s = cv2.getTrackbarPos(switch, 'Image')\n",
    "    \n",
    "    if s == 0:\n",
    "        img[:] = 0\n",
    "    else:\n",
    "        img[:] = [b, g, r]\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paint application with variable brush radius\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "drawing =  False\n",
    "\n",
    "# function for trackbar activities\n",
    "def nothing(arg):\n",
    "    pass\n",
    "\n",
    "\n",
    "def draw_paint(event, x, y, flags, params):\n",
    "    global drawing\n",
    "    \n",
    "    # get radius from trackbar position\n",
    "    radius = cv2.getTrackbarPos('Radius', 'Paint App')\n",
    "    \n",
    "    # select color from trackbar position\n",
    "    r = cv2.getTrackbarPos('R', 'Paint App')\n",
    "    b = cv2.getTrackbarPos('B', 'Paint App')\n",
    "    g = cv2.getTrackbarPos('G', 'Paint App')\n",
    "    \n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "    \n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if drawing == True:\n",
    "            cv2.circle(img, (x, y), radius, (b, g, r), -1)\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        drawing = False\n",
    "        cv2.circle(img, (x, y), radius, (b, g, r), -1)\n",
    "\n",
    "\n",
    "# define a window and image\n",
    "img = np.ones((512, 512, 3), np.uint8)\n",
    "cv2.namedWindow('Paint App',  cv2.WINDOW_NORMAL)\n",
    "cv2.setMouseCallback('Paint App', draw_paint)\n",
    "\n",
    "# Create trackbars for radius and color selections\n",
    "cv2.createTrackbar('Radius', 'Paint App', 1, 20, nothing)\n",
    "cv2.createTrackbar('R', 'Paint App', 10, 255, nothing)\n",
    "cv2.createTrackbar('G', 'Paint App', 10, 255, nothing)\n",
    "cv2.createTrackbar('B', 'Paint App', 10, 255, nothing)\n",
    "\n",
    "while True:\n",
    "    cv2.imshow('Paint App', img)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Operations on Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Operations on Images - Borders\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "BLUE = [255,0,0]\n",
    "img = cv2.imread('Learning/messi.jpg')\n",
    "\n",
    "imgReplicate = cv2.copyMakeBorder(img, 10, 10, 10, 10, cv2.BORDER_REPLICATE)\n",
    "imgReflect = cv2.copyMakeBorder(img, 20, 20, 20, 20, cv2.BORDER_REFLECT)\n",
    "imgReflect101 = cv2.copyMakeBorder(img, 20, 20, 20, 20, cv2.BORDER_REFLECT_101)\n",
    "imgWarp = cv2.copyMakeBorder(img, 20, 20, 20, 20, cv2.BORDER_WRAP)\n",
    "imgConstant= cv2.copyMakeBorder(img,10,10,10,10,cv2.BORDER_CONSTANT,value=BLUE)\n",
    "\n",
    "cv2.imshow('Image', imgConstant)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Operations on Images - Blending\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img1 = cv2.imread('Learning/opencv_logo.png')\n",
    "img2 = cv2.imread('Learning/ml.png')\n",
    "\n",
    "print(img1.shape)\n",
    "print(img2.shape)\n",
    "\n",
    "imgBlend = cv2.addWeighted(img1, 0.5, img2, 0.5, 0)\n",
    "\n",
    "cv2.imshow('Image', imgBlend)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Operations on Images - Bitwise operations\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# open both images\n",
    "imgMessi = cv2.imread('Learning/messi.jpg')\n",
    "imgOpencv = cv2.imread('Learning/opencv_logo.png')\n",
    "\n",
    "# put logon top-left corner of the image. Create a ROI\n",
    "rows, cols, channels = imgOpencv.shape\n",
    "roi = imgMessi[0:rows, 0:cols]\n",
    "\n",
    "# create a mask of logo and its inverse mask also\n",
    "imgOpencvGray = cv2.cvtColor(imgOpencv, cv2.COLOR_BGR2GRAY)\n",
    "ret, mask = cv2.threshold(imgOpencvGray, 10, 255, cv2.THRESH_BINARY)\n",
    "mask_inv = cv2.bitwise_not(mask)\n",
    "\n",
    "# black out the area of the logo in ROI\n",
    "imgMessi_bg = cv2.bitwise_and(roi, roi, mask=mask_inv)\n",
    "\n",
    "# Take only region of logo from logo image.\n",
    "imgOpencv_fg = cv2.bitwise_and(imgOpencv, imgOpencv, mask=mask)\n",
    "\n",
    "# Put logo in ROI and modify the main image\n",
    "dst = cv2.add(imgMessi_bg, imgOpencv_fg)\n",
    "imgMessi[0:rows, 0:cols] = dst\n",
    "\n",
    "cv2.imshow('Image', imgMessi)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing Colorspaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object Tracking\n",
    "\n",
    "# Take each frame of the video\n",
    "# Convert from BGR to HSV color-space\n",
    "# We threshold the HSV image for a range of blue color\n",
    "# Now extract the blue object alone, we can do whatever on that image we want.\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # take each frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # convert to HSV\n",
    "    frame_hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # define the range of blue color in HSV\n",
    "    lower_blue = np.array([110, 50, 50])\n",
    "    upper_blue = np.array([130, 255, 255])\n",
    "    \n",
    "    # threshold the HSV to get only blue values\n",
    "    mask = cv2.inRange(frame_hsv, lower_blue, upper_blue)\n",
    "    \n",
    "    # bitwise_and mask and original image\n",
    "    imgFinal = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "    \n",
    "    cv2.imshow('Video', imgFinal)\n",
    "    k = cv2.waitKey(20) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object Tracking - Multiple color selection\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "def nothing(arg):\n",
    "    pass\n",
    "\n",
    "# Creating window\n",
    "cv2.namedWindow('Result', cv2.WINDOW_NORMAL)\n",
    "\n",
    "# initialize h, s, v values to prevent masking error\n",
    "h, s, v = 100, 100, 100\n",
    "\n",
    "# Creating trackbar for selecting mask\n",
    "cv2.createTrackbar('Hue Min', 'Result', 0, 179, nothing)\n",
    "cv2.createTrackbar('Hue Max', 'Result', 19, 179, nothing)\n",
    "cv2.createTrackbar('Sat Min', 'Result', 110, 255, nothing)\n",
    "cv2.createTrackbar('Sat Max', 'Result', 240, 255, nothing)\n",
    "cv2.createTrackbar('Val Min', 'Result', 153, 255, nothing)\n",
    "cv2.createTrackbar('Val Max', 'Result', 255, 255, nothing)\n",
    "\n",
    "while True:\n",
    "    # take each frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # convert to HSV\n",
    "    frame_hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # get info from trackbar\n",
    "    hue_min = cv2.getTrackbarPos('Hue Min', 'Result')\n",
    "    hue_max = cv2.getTrackbarPos('Hue Max', 'Result')\n",
    "    sat_min = cv2.getTrackbarPos('Sat Min', 'Result')\n",
    "    sat_max = cv2.getTrackbarPos('Sat Max', 'Result')\n",
    "    val_min = cv2.getTrackbarPos('Val Min', 'Result')\n",
    "    val_max = cv2.getTrackbarPos('Val Max', 'Result')\n",
    "    \n",
    "    # define the range of blue color in HSV\n",
    "    lower_blue = np.array([hue_min, sat_min, val_min])\n",
    "    upper_blue = np.array([hue_max, sat_max, val_max])\n",
    "    \n",
    "    # threshold the HSV to get only blue values\n",
    "    mask = cv2.inRange(frame_hsv, lower_blue, upper_blue)\n",
    "    \n",
    "    # bitwise_and mask and original image\n",
    "    imgFinal = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "    \n",
    "    cv2.imshow('Result', imgFinal)\n",
    "    k = cv2.waitKey(20) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Simple Thresholding\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread('Learning/gradient.png')\n",
    "\n",
    "ret, thresh1 = cv2.threshold(img, 127,255, cv2.THRESH_BINARY)\n",
    "ret, thresh2 = cv2.threshold(img, 127,255, cv2.THRESH_BINARY_INV)\n",
    "ret, thresh3 = cv2.threshold(img, 127,255, cv2.THRESH_TRUNC)\n",
    "ret, thresh4 = cv2.threshold(img, 127,255, cv2.THRESH_TOZERO)\n",
    "ret, thresh5 = cv2.threshold(img, 127,255, cv2.THRESH_TOZERO_INV)\n",
    "\n",
    "titles = ['Original Image','BINARY','BINARY_INV','TRUNC','TOZERO','TOZERO_INV']\n",
    "images = [img, thresh1, thresh2, thresh3, thresh4, thresh5]\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.imshow(images[i], 'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Adaptive Thresholding\n",
    "\n",
    "import numpy\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread('Learning/sudoku-original.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#img = cv2.medianBlur(img, 5)\n",
    "\n",
    "ret, th1 = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
    "th2 = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 41, 2)\n",
    "th3 = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 41, 2)\n",
    "\n",
    "titles = ['Original Image','Global Threshold (v = 127)','Adaptive Mean Thresholding','Adaptive Gaussian Thresholding']\n",
    "images = [img, th1, th2, th3]\n",
    "\n",
    "for i in range(4):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.imshow(images[i], 'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geometric Transformations of Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations - scaling\n",
    "\n",
    "import numpy\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('Learning/messi.jpg')\n",
    "\n",
    "# method 1\n",
    "imgRes1 = cv2.resize(img, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "# method 2\n",
    "height, width = img.shape[:2]\n",
    "imgRes2 = cv2.resize(img, (2*width, 2*height), interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "cv2.imshow('Resized Image1', imgRes1)\n",
    "cv2.imshow('Resized Image2', imgRes2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations - Translation\n",
    "# Translation is the shifting of object’s location\n",
    "\n",
    "import numpy\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('Learning/messi.jpg')\n",
    "rows, cols = img.shape[:2]\n",
    "\n",
    "# create the transformation matrix \\textbf{M}\n",
    "M = np.float32([[1, 0, 100], [0, 1, 50]])\n",
    "imgResult = cv2.warpAffine(img, M, (cols, rows))\n",
    "\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('Result Image', imgResult)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations - Rotation\n",
    "\n",
    "import numpy\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('Learning/messi.jpg')\n",
    "rows, cols = img.shape[:2]\n",
    "\n",
    "M = cv2.getRotationMatrix2D((rows/2, cols/2), 90, 1)\n",
    "imgResult = cv2.warpAffine(img, M, (cols, rows))\n",
    "\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('Result Image', imgResult)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations - Perspective Transformation\n",
    "\n",
    "import numpy\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('Learning/sudoku-original.jpg')\n",
    "\n",
    "pts1 = np.float32([[54, 62], [370, 52], [26, 389], [391, 392]])\n",
    "pts2 = np.float32([[0, 0], [300, 0], [0, 300], [300, 300]])\n",
    "\n",
    "M = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "imgResult = cv2.warpPerspective(img, M, (300, 300))\n",
    "\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('Result Image', imgResult)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothing Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D Convolution ( Image Filtering )\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread('Learning/opencv_logo.png')\n",
    "\n",
    "# define kernal\n",
    "kernal = np.ones((5, 5), np.float32)/25\n",
    "#print(kernal)\n",
    "\n",
    "# Apply kernal\n",
    "imgResult = cv2.filter2D(img, -1, kernal)\n",
    "          \n",
    "    \n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img)\n",
    "plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(imgResult)\n",
    "plt.title('Averaging')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Image Blurring (Image Smoothing) - Averaging\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread('Learning/opencv_logo.png')\n",
    "\n",
    "imgBlur = cv2.blur(img, (5, 5))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img)\n",
    "plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(imgBlur)\n",
    "plt.title('Blurred')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Image Blurring (Image Smoothing) - Gaussian Filtering\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread('Learning/opencv_logo.png')\n",
    "\n",
    "imgBlur = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img)\n",
    "plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(imgBlur)\n",
    "plt.title('Blurred')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laplacian Derivatives & Sobel Derivatives\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('Learning/sudoku-original.jpg')\n",
    "#imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "laplacian = cv2.Laplacian(img, cv2.CV_64F)\n",
    "sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=5)\n",
    "sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=5)\n",
    "\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('Laplacian', laplacian)\n",
    "cv2.imshow('Sobel-x', sobelx)\n",
    "cv2.imshow('Sobel-y', sobely)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canny Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canny Edge Detection\n",
    "\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('Learning/messi.jpg')\n",
    "\n",
    "imgCanny = cv2.Canny(img, 100, 200)\n",
    "\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('Canny Image', imgCanny)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# find contours of a binary image\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Function to stack images\n",
    "def stackImages(scale, imgArray):\n",
    "    rows = len(imgArray)\n",
    "    cols = len(imgArray[0])\n",
    "    rowsAvailable = isinstance(imgArray[0], list)\n",
    "    width = imgArray[0][0].shape[1]\n",
    "    height = imgArray[0][0].shape[0]\n",
    "\n",
    "    if rowsAvailable:\n",
    "        for x in range(0, rows):\n",
    "            for y in range(0, cols):\n",
    "                if imgArray[x][y].shape[:2] == imgArray[0][0].shape[:2]:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (0, 0), None, scale, scale)\n",
    "                else:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]), None, scale, scale)\n",
    "                if len(imgArray[x][y].shape) == 2: imgArray[x][y]= cv2.cvtColor( imgArray[x][y], cv2.COLOR_GRAY2BGR)\n",
    "        imageBlank = np.zeros((height, width, 3), np.uint8)\n",
    "        hor = [imageBlank]*rows\n",
    "        hor_con = [imageBlank]*rows\n",
    "        for x in range(0, rows):\n",
    "            hor[x] = np.hstack(imgArray[x])\n",
    "        ver = np.vstack(hor)\n",
    "    else:\n",
    "        for x in range(0, rows):\n",
    "            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (0, 0), None, scale, scale)\n",
    "            else:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None,scale, scale)\n",
    "            if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)\n",
    "        hor= np.hstack(imgArray)\n",
    "        ver = hor\n",
    "    return ver\n",
    "\n",
    "def getContours(img):\n",
    "    contours, hierachy = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        #print('Area: ', area)\n",
    "\n",
    "        if area > 500 : # this check will confirm the area greater than threshold value to avoid noise\n",
    "            cv2.drawContours(imgContour, cnt, -1, (255, 0, 0), 3)\n",
    "            peri = cv2.arcLength(cnt, True)\n",
    "            #print('Perimeter:', peri)\n",
    "            approx = cv2.approxPolyDP(cnt, 0.02*peri, True)\n",
    "            print('Approximate Corners: ', len(approx))\n",
    "            objCorner = len(approx)\n",
    "            x, y, w, h = cv2.boundingRect(approx)\n",
    "\n",
    "            if objCorner == 3:\n",
    "                objType = 'Triangle'\n",
    "            elif objCorner == 4:\n",
    "                aspRatio = w/float(h)\n",
    "                if aspRatio > 0.95 and aspRatio < 1.05:\n",
    "                    objType = 'Square'\n",
    "                else:\n",
    "                    objType = 'Rectangle'\n",
    "            elif objCorner > 4:\n",
    "                objType = 'Circle'\n",
    "            else:\n",
    "                objType = 'Other'\n",
    "\n",
    "            cv2.rectangle(imgContour, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            cv2.putText(imgContour, objType,\n",
    "                        (x+(w//2)-10, y+(h//2)-10),\n",
    "                        cv2.FONT_HERSHEY_COMPLEX,\n",
    "                        0.7,\n",
    "                        (0, 0, 0), 2)\n",
    "            \n",
    "img = cv2.imread('Resources/shapes.png')\n",
    "imgContour = img.copy()\n",
    "\n",
    "imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "imgBlur = cv2.GaussianBlur(imgGray, (7, 7), 1)\n",
    "imgCanny = cv2.Canny(imgBlur, 50, 50)\n",
    "\n",
    "getContours(imgCanny)\n",
    "\n",
    "imgBlank = np.zeros_like(img)\n",
    "imgStack = stackImages(0.5, ([img, imgGray, imgBlur],\n",
    "                             [imgCanny, imgContour, imgBlank]))\n",
    "cv2.imshow('Stack Image', imgStack)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# face detection in a video\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('Resources/haarcascades/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('Resources/haarcascades/haarcascade_eye.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "cv2.namedWindow('Video Frame', cv2.WINDOW_NORMAL)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    frameGray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(frameGray, 1.3, 5)\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        img = cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = frame[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "    \n",
    "    cv2.imshow('Video Frame', frame)\n",
    "    k = cv2.waitKey(10) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background Subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3))\n",
    "fgbg = cv2.createBackgroundSubtractorKNN()\n",
    "\n",
    "while(1):\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    fgmask = fgbg.apply(frame)\n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    cv2.imshow('frame',fgmask)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Scanner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document Scanner from video \n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Define Global variables\n",
    "imgWidth = 640\n",
    "imgHeight = 480\n",
    "\n",
    "# function to perprocess image\n",
    "def perProcessing(img):\n",
    "    imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    imgBlur = cv2.GaussianBlur(imgGray, (5, 5), 1)\n",
    "    imgCanny = cv2.Canny(imgBlur, 200, 200)\n",
    "    kernal = np.ones((5, 5))\n",
    "    imgDilation = cv2.dilate(imgCanny, kernal, iterations=2)\n",
    "    imgThreshold = cv2.erode(imgDilation, kernal, iterations=2)\n",
    "    \n",
    "    return imgThreshold\n",
    "\n",
    "\n",
    "# function to find countours and draw\n",
    "def getContours(img):\n",
    "    maxArea = 0\n",
    "    biggest = np.array([])\n",
    "    contours, hierarchy = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    for contour in contours:\n",
    "        cntArea = cv2.contourArea(contour)\n",
    "        if cntArea > 5000:\n",
    "            cv2.drawContours(imgContour, contour, -1, (255, 0, 0), 3)\n",
    "            perimeter = cv2.arcLength(contour, True)\n",
    "            approx = cv2.approxPolyDP(contour, 0.02 * perimeter, True)\n",
    "            if cntArea > maxArea & len(approx) == 4:\n",
    "                biggest = approx\n",
    "                maxArea = area\n",
    "    #cv2.drawContours(imgContour, biggest, -1, (255, 0, 0), 20)\n",
    "    return biggest\n",
    "\n",
    "\n",
    "# function to reorder points\n",
    "def reorderPoints(points):\n",
    "    points = points.reshape((4,2))\n",
    "    pointsNew = np.zeros((4,1,2), np.int32)\n",
    "    \n",
    "    add = points.sum(1)\n",
    "    pointsNew[0] = points[np.argmin(add)]\n",
    "    pointsNew[4] = points[np.argmax(add)]\n",
    "    \n",
    "    diff = points.diff(1)\n",
    "    pointsNew[1] = points[np.argmin(diff)]\n",
    "    pointsNew[2] = points[np.argmax(diff)]\n",
    "    \n",
    "    return pointsNew\n",
    "\n",
    "\n",
    "# get warp perspective from biggest contour points\n",
    "def getWarp(img, biggest):\n",
    "    biggest = reorderPoints(biggest)\n",
    "    pts1 = np.float32(biggest)\n",
    "    pts2 = np.float32([[0, 0], [imgWidth, 0], [0, imgHeight], [imgWidth, imgHeight]])\n",
    "    matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "    imgOutput = cv2.warpPerspective(img, matrix, (imgWidth, imgHeight))\n",
    "    imgCropped = imgOutput[20:imgOutput.shape[0]-20, 20:imgOutput.shape[1]-20] # Crop image by 20 pixels\n",
    "    imgCropped = cv2.resize(imgCropped, (imgWidth, imgHeight))\n",
    "    return imgCropped\n",
    "\n",
    "\n",
    "# capture video from webcam and set properties\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, imgWidth)\n",
    "cap.set(4, imgHeight)\n",
    "cap.set(10, 150)\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "    \n",
    "    img = cv2.resize(img, (imgWidth, imgHeight))\n",
    "    imgContour = img.copy()\n",
    "    \n",
    "    imgThresh = perProcessing(img)\n",
    "    biggest = getContours(imgThresh)\n",
    "    #print(biggest)\n",
    "    \n",
    "    if biggest.size != 0 :\n",
    "        imgWarp = getWarp(img, biggest)\n",
    "        cv2.imshow('Video', imgWarp)\n",
    "    else:\n",
    "        cv2.imshow('Video', img)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number Plate Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number plate detection\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "licenseCascade = cv2.CascadeClassifier('Resources/haarcascades/haarcascade_russian_plate_number.xml')\n",
    "\n",
    "# capture video from webcam and set properties\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "cap.set(10, 150)\n",
    "\n",
    "count = 1\n",
    "\n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "    imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    licensePlates = licenseCascade.detectMultiScale(imgGray, 1.1, 4)\n",
    "\n",
    "    minArea = 500\n",
    "    for (x, y, w, h) in licensePlates:\n",
    "        area = w * h\n",
    "        if area > minArea:\n",
    "            cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 3)\n",
    "            cv2.putText(img, 'Number Plate', (x, y-5), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 255, 255), 2)\n",
    "            imgRoi = img[y:y+h, x:x+w]\n",
    "            cv2.imshow('Number Plate', imgRoi)\n",
    "\n",
    "    cv2.imshow('Original Image', img)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "        cv2.imwrite('Learning/Number_plate_'+str(count)+'.jpg', imgRoi)\n",
    "        cv2.rectangle(img, (0, 200), (640, 300), (0, 255, 0), cv2.FILLED)\n",
    "        cv2.putText(img, 'Scan Saved', (150, 265), cv2.FONT_HERSHEY_DUPLEX, 2, (0, 255, 255), 2)\n",
    "        cv2.imshow('Original Image', img)\n",
    "        cv2.waitKey(500)\n",
    "        count += 1\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
